# Adaptive UI Agent

> **Agente de RL Visual que aprende a executar tarefas UI a partir de linguagem natural**

Baseado no paper **arXiv 2312.01203v3**: "Harnessing Discrete Representations for Continual RL"

---

## ğŸ§  Arquitetura

```
User (texto) â†’ LLM â†’ Plan (JSON) â†’ Translator â†’ Reward â†’ RL (PPO) â†’ AÃ§Ãµes
                                                            â†‘
                                    Pixels â†’ VQ-VAE â†’ Multi-One-Hot
```

> **LLM nunca toca no mouse. RL nunca lÃª texto.**

---

## âš¡ Quick Start

```bash
# 1. Instalar
pip install -r requirements.txt

# 2. Configurar LLM (copie e edite)
cp configs/llm_config.example.yaml configs/llm_config.yaml
# Edite com sua API key

# 3. Executar modo interativo
python planner/integration.py --interactive
```

---

## ğŸ”‘ Providers LLM Suportados

| Provider | Modelos | API Key Env |
|----------|---------|-------------|
| OpenAI | gpt-5.2-instant/thinking/pro | `OPENAI_API_KEY` |
| Anthropic | claude-4.5-opus/sonnet/haiku | `ANTHROPIC_API_KEY` |
| Google | gemini-2.5-flash/pro | `GOOGLE_API_KEY` |
| xAI | grok-4, grok-4.1 | `XAI_API_KEY` |
| Ollama | llama4, qwen3, gemma3 | (local) |

```bash
# Uso com provider especÃ­fico
python planner/integration.py --provider anthropic --interactive
```

---

## ğŸ“– DocumentaÃ§Ã£o

- **[Guia Completo](docs/GUIA_COMPLETO.md)** - InstalaÃ§Ã£o, configuraÃ§Ã£o, uso detalhado
- **[LLM Config](configs/llm_config.example.yaml)** - ConfiguraÃ§Ã£o de API keys
- **[Arquitetura](docs/GUIA_COMPLETO.md#arquitetura)** - Diagrama e fluxo de dados

---

## ğŸ“ Estrutura

```
â”œâ”€â”€ planner/          # LLM-RL Integration
â”‚   â”œâ”€â”€ goal_dsl.py       # Visual vocabulary
â”‚   â”œâ”€â”€ llm_planner.py    # LLM â†’ Plan
â”‚   â”œâ”€â”€ llm_provider.py   # Universal LLM (LiteLLM)
â”‚   â””â”€â”€ integration.py    # Full pipeline
â”œâ”€â”€ vision/           # VQ-VAE (discrete encoding)
â”œâ”€â”€ agent/            # PPO (policy learning)
â”œâ”€â”€ env/              # Pygame sandbox (64Ã—64)
â””â”€â”€ configs/          # Hyperparameters + LLM keys
```

---

## ğŸ¯ Exemplo

```python
from planner import LLMRLIntegration

agent = LLMRLIntegration(llm_provider="openai")
result = agent.train_on_goal("Cria 3 quadrados azuis alinhados")

print(f"Sucesso: {result.success}")
print(f"Taxa: {result.final_success_rate:.1%}")
```

---

*Janeiro 2026 | Paper: arXiv 2312.01203v3*
